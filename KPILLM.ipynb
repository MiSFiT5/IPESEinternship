{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LLM aided Decision Making in MCDA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "openai api key is needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from openai import OpenAI\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display, clear_output\n",
    "import os\n",
    "\n",
    "\n",
    "file_path = 'Your Path of the KPI file'\n",
    "data = pd.read_csv(file_path)\n",
    "\n",
    "# data Normalization\n",
    "scaler = MinMaxScaler()\n",
    "normalized_data = pd.DataFrame(scaler.fit_transform(data), columns=data.columns)\n",
    "\n",
    "# initialize weights\n",
    "initial_weights = {column: 1/len(normalized_data.columns) for column in normalized_data.columns}\n",
    "\n",
    "# instance creation client\n",
    "client = OpenAI(api_key=os.environ.get(\"OPENAI_API_KEY\", \"YOUR OPENAI API KEY\"))\n",
    "\n",
    "# weighted sum\n",
    "def calculate_weighted_sum(data, weights):\n",
    "    weighted_sum = np.dot(data, np.array([weights[col] for col in data.columns]))\n",
    "    return weighted_sum\n",
    "\n",
    "# iteration updates\n",
    "def update_ranking(weights):\n",
    "    # call weighted sum functions\n",
    "    scores = calculate_weighted_sum(normalized_data, weights)\n",
    "    \n",
    "    # add scores to dataframe\n",
    "    ranked_data = normalized_data.copy()\n",
    "    ranked_data['Score'] = scores\n",
    "    \n",
    "    # ranking\n",
    "    ranked_data = ranked_data.sort_values(by='Score', ascending=False)\n",
    "    \n",
    "    # Top 5 configurations\n",
    "    with out:\n",
    "        clear_output(wait=True)\n",
    "        print(\"Top 5 configurations based on current weights:\")\n",
    "        display(ranked_data.head())\n",
    "        \n",
    "        # radar map\n",
    "        create_radar_chart(ranked_data.iloc[0].drop('Score').values, normalized_data.columns.tolist(), \n",
    "                           baseline=baseline)\n",
    "\n",
    "# GPT functions for weight adjustment\n",
    "def adjust_weights_with_gpt4(weights, top_configurations, radar_data):\n",
    "    radar_info = \"Current radar chart data:\\n\"\n",
    "    for kpi, values in radar_data.items():\n",
    "        radar_info += f\"{kpi}: Current Value: {values['current']}, Baseline: {values['baseline']}\\n\"\n",
    "    \n",
    "    prompt = (\n",
    "        f\"Given the following top configurations and their current weights:\\n{top_configurations}\\n\\n\"\n",
    "        f\"The current weights are:\\n{weights}\\n\\n\"\n",
    "        f\"{radar_info}\\n\"\n",
    "        \"Please suggest new weights for each KPI to improve the configuration performance on environmental impacts. \"\n",
    "        \"Imagine three different problem-solving experts are answering this question, and five judgment experts are voting for each step. Assign the weights to each KPI based on the experts' voting. \"\n",
    "        \"Return the weights in the following exact format (no explanations): 'KPI1: weight1, KPI2: weight2, ...'. \"\n",
    "        \"Ensure all KPIs are included, and the weights sum up to 1.\"\n",
    "    )\n",
    "    \n",
    "    response = client.chat.completions.create(\n",
    "        model=\"gpt-4\",\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": \"You are a data optimization expert.\"},\n",
    "            {\"role\": \"user\", \"content\": prompt},\n",
    "        ],\n",
    "        max_tokens=150,\n",
    "        temperature=0.7\n",
    "    )\n",
    "    \n",
    "    gpt_response = response.choices[0].message.content.strip()\n",
    "    print(f\"GPT-4 Response: {gpt_response}\")\n",
    "    \n",
    "    try:\n",
    "        gpt_response = gpt_response.replace(\"'\", \"\").replace(\" \", \"\")\n",
    "        new_weights = {}\n",
    "        for item in gpt_response.split(','):\n",
    "            kpi, weight = item.split(':')\n",
    "            new_weights[kpi.strip()] = float(weight.strip())\n",
    "        \n",
    "        if set(new_weights.keys()) != set(weights.keys()):\n",
    "            print(\"Incomplete response from GPT-4, using original weights.\")\n",
    "            return weights\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Failed to parse GPT-4 response: {e}, using original weights.\")\n",
    "        new_weights = weights\n",
    "\n",
    "    return new_weights\n",
    "\n",
    "# weights iteration optimization\n",
    "def iterative_weight_optimization(weights, iterations=5):\n",
    "    for i in range(iterations):\n",
    "        print(f\"Iteration {i+1}\")\n",
    "        \n",
    "        # Calculate scores and ranking\n",
    "        scores = calculate_weighted_sum(normalized_data, weights)\n",
    "        ranked_data = normalized_data.copy()\n",
    "        ranked_data['Score'] = scores\n",
    "        ranked_data = ranked_data.sort_values(by='Score', ascending=False)\n",
    "        \n",
    "        # Get top 5 configurations for feedback to GPT-4\n",
    "        top_configurations = ranked_data.head().to_string()\n",
    "        \n",
    "        # Prepare radar chart data for GPT-4\n",
    "        top_data_point = ranked_data.iloc[0].drop('Score').values\n",
    "        radar_data = {\n",
    "            label: {\"current\": top_data_point[i], \"baseline\": baseline[i]}\n",
    "            for i, label in enumerate(normalized_data.columns)\n",
    "        }\n",
    "        \n",
    "        # Update weights using GPT-4\n",
    "        weights = adjust_weights_with_gpt4(weights, top_configurations, radar_data)\n",
    "        \n",
    "        # Update ranking and display results\n",
    "        update_ranking(weights)\n",
    "    \n",
    "    return weights\n",
    "\n",
    "\n",
    "# radar chart generation function\n",
    "def create_radar_chart(data_point, labels, baseline, title='Radar Map'):\n",
    "    num_vars = len(labels)\n",
    "    angles = np.linspace(0, 2 * np.pi, num_vars, endpoint=False).tolist()\n",
    "    angles += angles[:1]\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(8, 8), subplot_kw=dict(polar=True))\n",
    "\n",
    "    data_point = data_point.tolist()\n",
    "    data_point += data_point[:1]\n",
    "    ax.plot(angles, data_point, linewidth=2, linestyle='solid', label='Selected Data')\n",
    "    ax.fill(angles, data_point, alpha=0.25)\n",
    "\n",
    "    baseline = baseline.tolist()\n",
    "    baseline += baseline[:1]\n",
    "    ax.plot(angles, baseline, color='red', linewidth=2, linestyle='dashed', label='Baseline')\n",
    "    ax.fill(angles, baseline, color='red', alpha=0.15)\n",
    "\n",
    "    ax.set_xticks(angles[:-1])\n",
    "    ax.set_xticklabels(labels)\n",
    "    ax.set_yticklabels([])\n",
    "    ax.set_ylim(min(min(data_point), min(baseline)), max(max(data_point), max(baseline)))\n",
    "\n",
    "    plt.title(title, size=20, position=(0.5, 1.1))\n",
    "    plt.legend(loc='upper right', bbox_to_anchor=(0.1, 0.1))\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "# display widgets and output\n",
    "out = widgets.Output()\n",
    "\n",
    "# display\n",
    "display(out)\n",
    "\n",
    "# initialization and optimization\n",
    "final_weights = iterative_weight_optimization(initial_weights, iterations=5)\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
